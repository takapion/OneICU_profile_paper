{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "678ac383",
   "metadata": {},
   "source": [
    "# h2o automl training pipeline (binomial) with stacked ensembles\n",
    "\n",
    "this notebook trains models to predict `outcome_lead` using all variables except:\n",
    "- `icu_stay_id`\n",
    "- `time_window_index`\n",
    "\n",
    "for each dataset (`oneicu`, `eicu`, `mimiciv`), we:\n",
    "1. load the previously created train/test csvs from `../data/machine_learning`\n",
    "2. train h2o automl (stacked ensembles **included**, nothing excluded)\n",
    "3. save the **best overall model** and the **best glm** into `../data/machine_learning/models/<dataset>/`\n",
    "4. write a manifest for later evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdd2e01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n",
      "Warning: Your H2O cluster version is (5 months and 8 days) old.  There may be a newer version available.\n",
      "Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>1 day 1 hour 20 mins</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Asia/Tokyo</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.7</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>5 months and 8 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_kinoshitatakashihiroshi_xo9ujw</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>5.248 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.12.3 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------------\n",
       "H2O_cluster_uptime:         1 day 1 hour 20 mins\n",
       "H2O_cluster_timezone:       Asia/Tokyo\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.7\n",
       "H2O_cluster_version_age:    5 months and 8 days\n",
       "H2O_cluster_name:           H2O_from_python_kinoshitatakashihiroshi_xo9ujw\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    5.248 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.12.3 final\n",
       "--------------------------  ----------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "\n",
    "import gc\n",
    "\n",
    "# paths\n",
    "data_dir = Path(\"../data/machine_learning\")\n",
    "models_root = Path(\"../output/models\")\n",
    "models_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# datasets to train\n",
    "datasets = [\"oneicu\", \"eicu\", \"mimiciv\"]\n",
    "\n",
    "# columns\n",
    "id_col = \"icu_stay_id\"\n",
    "time_index_col = \"time_window_index\"\n",
    "target = \"outcome_lead\"\n",
    "\n",
    "# automl settings (adjust as you like)\n",
    "aml_seed = 813\n",
    "aml_max_runtime_secs = 60*60*3\n",
    "aml_sort_metric = \"AUC\"\n",
    "\n",
    "# logging\n",
    "logging.basicConfig(level=20, format=\"%(asctime)s %(levelname)s %(message)s\")\n",
    "\n",
    "# start h2o\n",
    "h2o.init()\n",
    "h2o.no_progress()  # hide per-iteration progress; comment this line to see progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa98fc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_train_pd(dataset_name):\n",
    "    \"\"\"\n",
    "    read train csv into a pandas dataframe (fast), with minimal dtype fuss.\n",
    "    \"\"\"\n",
    "    train_path = data_dir / f\"ml_{dataset_name}_train.csv\"\n",
    "    if not train_path.exists():\n",
    "        raise FileNotFoundError(f\"missing train file for {dataset_name} under {data_dir}\")\n",
    "    # low_memory=False avoids mixed-type inference churn on large csvs\n",
    "    df = pd.read_csv(train_path, low_memory=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_patient_level_pd(df, id_col, seed=813, blend_frac=0.10, lb_frac=0.10):\n",
    "    \"\"\"\n",
    "    split a pandas dataframe into base/blend/leaderboard by unique patient (icu_stay_id).\n",
    "    \"\"\"\n",
    "    uniq = df[id_col].unique()\n",
    "    rng = np.random.default_rng(seed)\n",
    "    rng.shuffle(uniq)\n",
    "\n",
    "    n = len(uniq)\n",
    "    n_blend = int(n * blend_frac)\n",
    "    n_lb    = int(n * lb_frac)\n",
    "\n",
    "    blend_ids = set(uniq[:n_blend])\n",
    "    lb_ids    = set(uniq[n_blend:n_blend + n_lb])\n",
    "    base_ids  = set(uniq[n_blend + n_lb:])\n",
    "\n",
    "    blend_pd = df.loc[df[id_col].isin(blend_ids), :].reset_index(drop=True)\n",
    "    lb_pd    = df.loc[df[id_col].isin(lb_ids), :].reset_index(drop=True)\n",
    "    base_pd  = df.loc[df[id_col].isin(base_ids), :].reset_index(drop=True)\n",
    "\n",
    "    return base_pd, blend_pd, lb_pd\n",
    "\n",
    "\n",
    "def to_h2o_binomial_numeric(df_pd, target, features):\n",
    "    \"\"\"\n",
    "    convert pandas -> H2OFrame, enforce numeric features, and set binomial target.\n",
    "    \"\"\"\n",
    "    hf = h2o.H2OFrame(df_pd)\n",
    "    for c in features:\n",
    "        hf[c] = hf[c].asnumeric()\n",
    "    hf[target] = hf[target].asfactor()\n",
    "    return hf\n",
    "\n",
    "\n",
    "def feature_columns(hf, target, drop_cols):\n",
    "    \"\"\"\n",
    "    return feature column names = all columns minus target and drop_cols that exist.\n",
    "    \"\"\"\n",
    "    cols = [c for c in hf.columns if c != target and c not in drop_cols and c in hf.columns]\n",
    "    return cols\n",
    "\n",
    "\n",
    "def best_glm_from_automl(aml):\n",
    "    \"\"\"\n",
    "    fetch the best glm trained during automl by auc (fallback to aucpr/logloss).\n",
    "    raises if none is present.\n",
    "    \"\"\"\n",
    "    lb_df = aml.leaderboard.as_data_frame()\n",
    "    glm_rows = lb_df[lb_df[\"model_id\"].str.contains(\"GLM_\", na=False)]\n",
    "\n",
    "    if glm_rows.empty:\n",
    "        raise RuntimeError(\"automl did not produce a glm model. consider increasing max_runtime_secs or nfolds.\")\n",
    "\n",
    "    glm_rows = glm_rows.sort_values(\"auc\", ascending=False)\n",
    "    \n",
    "    best_glm_id = glm_rows.iloc[0][\"model_id\"]\n",
    "    return h2o.get_model(best_glm_id)\n",
    "\n",
    "\n",
    "def save_models(dataset_name, leader, glm_model, x):\n",
    "    \"\"\"\n",
    "    save leader and glm under models_root/dataset_name and write a simple manifest.\n",
    "    \"\"\"\n",
    "    out_dir = (models_root / dataset_name)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    leader_path = h2o.save_model(model=leader, path=out_dir.as_posix(), force=True)\n",
    "    glm_path = h2o.save_model(model=glm_model, path=out_dir.as_posix(), force=True)\n",
    "\n",
    "    manifest = {\n",
    "        \"dataset\": dataset_name,\n",
    "        \"leader_model_path\": leader_path,\n",
    "        \"glm_model_path\": glm_path,\n",
    "        \"features\": x,\n",
    "        \"target\": target,\n",
    "        \"drop_columns\": [id_col, time_index_col],\n",
    "        \"automl_settings\": {\n",
    "            \"seed\": aml_seed,\n",
    "            \"nfolds\": 0,\n",
    "            \"sort_metric\": aml_sort_metric,\n",
    "        },\n",
    "    }\n",
    "    with open(out_dir / \"manifest.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(manifest, f, indent=2)\n",
    "    return leader_path, glm_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec082387",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 22:57:06,415 INFO === training dataset: oneicu ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "22:57:45.12: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      "\n",
      "=== leaderboard for oneicu (rows=22) ===\n",
      "                                                   model_id       auc   logloss     aucpr  mean_per_class_error      rmse       mse\n",
      "0      StackedEnsemble_AllModels_1_AutoML_1_20250904_225743  0.976367  0.129648  0.902373              0.104635  0.194257  0.037736\n",
      "1   StackedEnsemble_BestOfFamily_1_AutoML_1_20250904_225743  0.976210  0.130020  0.901833              0.100431  0.194601  0.037870\n",
      "2                            GBM_3_AutoML_1_20250904_225743  0.975939  0.130802  0.900988              0.104147  0.194995  0.038023\n",
      "3                            GBM_1_AutoML_1_20250904_225743  0.975919  0.130892  0.900698              0.100128  0.195254  0.038124\n",
      "4               GBM_grid_1_AutoML_1_20250904_225743_model_5  0.975917  0.130698  0.901287              0.102391  0.194842  0.037963\n",
      "5                            GBM_2_AutoML_1_20250904_225743  0.975907  0.130712  0.901166              0.104008  0.194870  0.037974\n",
      "6                            GBM_4_AutoML_1_20250904_225743  0.975836  0.131131  0.900398              0.097044  0.195342  0.038158\n",
      "7                            GBM_5_AutoML_1_20250904_225743  0.975779  0.131137  0.899886              0.099954  0.195067  0.038051\n",
      "8               GBM_grid_1_AutoML_1_20250904_225743_model_3  0.975769  0.131966  0.899209              0.102910  0.196216  0.038501\n",
      "9                            XRT_1_AutoML_1_20250904_225743  0.975696  0.131489  0.899402              0.100294  0.195736  0.038313\n",
      "10                           DRF_1_AutoML_1_20250904_225743  0.975691  0.131484  0.899314              0.102741  0.195798  0.038337\n",
      "11              GBM_grid_1_AutoML_1_20250904_225743_model_1  0.975612  0.132462  0.898655              0.105619  0.196584  0.038645\n",
      "12              GBM_grid_1_AutoML_1_20250904_225743_model_4  0.975523  0.132477  0.899305              0.099628  0.196186  0.038489\n",
      "13              GBM_grid_1_AutoML_1_20250904_225743_model_2  0.975333  0.133273  0.898241              0.104087  0.196779  0.038722\n",
      "14                  DeepLearning_1_AutoML_1_20250904_225743  0.971881  0.142561  0.886421              0.108128  0.201416  0.040568\n",
      "15     DeepLearning_grid_1_AutoML_1_20250904_225743_model_2  0.970317  0.143113  0.887175              0.103039  0.200838  0.040336\n",
      "16     DeepLearning_grid_2_AutoML_1_20250904_225743_model_2  0.969394  0.161511  0.885565              0.106843  0.210825  0.044447\n",
      "17                           GLM_1_AutoML_1_20250904_225743  0.969025  0.147295  0.887149              0.108989  0.202184  0.040879\n",
      "18     DeepLearning_grid_3_AutoML_1_20250904_225743_model_2  0.968603  0.170663  0.884760              0.110371  0.223556  0.049977\n",
      "19     DeepLearning_grid_3_AutoML_1_20250904_225743_model_1  0.968061  0.164798  0.882782              0.110944  0.211916  0.044909\n",
      "20     DeepLearning_grid_2_AutoML_1_20250904_225743_model_1  0.967686  0.160970  0.876284              0.111717  0.208602  0.043515\n",
      "21     DeepLearning_grid_1_AutoML_1_20250904_225743_model_1  0.964784  0.168347  0.877812              0.111561  0.215107  0.046271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kinoshitatakashihiroshi/Dropbox/VS_Code/OneICU_profile_paper/.venv/lib/python3.12/site-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n",
      "/Users/kinoshitatakashihiroshi/Dropbox/VS_Code/OneICU_profile_paper/.venv/lib/python3.12/site-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n",
      "2025-09-04 23:14:00,817 INFO === training dataset: eicu ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "23:14:12.389: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      "\n",
      "=== leaderboard for eicu (rows=22) ===\n",
      "                                                   model_id       auc   logloss     aucpr  mean_per_class_error      rmse       mse\n",
      "0      StackedEnsemble_AllModels_1_AutoML_2_20250904_231411  0.946315  0.168314  0.763660              0.164269  0.221667  0.049136\n",
      "1   StackedEnsemble_BestOfFamily_1_AutoML_2_20250904_231411  0.946045  0.168570  0.762705              0.165539  0.221861  0.049222\n",
      "2                            GBM_3_AutoML_2_20250904_231411  0.946013  0.169021  0.761668              0.165520  0.222137  0.049345\n",
      "3                            GBM_2_AutoML_2_20250904_231411  0.945903  0.169034  0.761859              0.163105  0.222045  0.049304\n",
      "4               GBM_grid_1_AutoML_2_20250904_231411_model_5  0.945720  0.168990  0.762445              0.154708  0.221924  0.049250\n",
      "5                            GBM_1_AutoML_2_20250904_231411  0.945712  0.169520  0.759074              0.154466  0.222635  0.049566\n",
      "6                            GBM_5_AutoML_2_20250904_231411  0.945591  0.169917  0.754560              0.164379  0.222526  0.049518\n",
      "7                            GBM_4_AutoML_2_20250904_231411  0.945111  0.170321  0.757930              0.162635  0.223181  0.049810\n",
      "8               GBM_grid_1_AutoML_2_20250904_231411_model_3  0.944365  0.171570  0.754629              0.162955  0.224103  0.050222\n",
      "9               GBM_grid_1_AutoML_2_20250904_231411_model_4  0.944338  0.172118  0.754373              0.164809  0.224221  0.050275\n",
      "10                           XRT_1_AutoML_2_20250904_231411  0.944283  0.170936  0.756284              0.162349  0.223361  0.049890\n",
      "11                           DRF_1_AutoML_2_20250904_231411  0.944247  0.170706  0.757416              0.164717  0.223080  0.049765\n",
      "12              GBM_grid_1_AutoML_2_20250904_231411_model_2  0.944024  0.172243  0.753709              0.159673  0.224246  0.050286\n",
      "13              GBM_grid_1_AutoML_2_20250904_231411_model_1  0.943246  0.172647  0.752637              0.157491  0.224737  0.050507\n",
      "14     DeepLearning_grid_2_AutoML_2_20250904_231411_model_2  0.939614  0.187944  0.743356              0.161133  0.234779  0.055121\n",
      "15                  DeepLearning_1_AutoML_2_20250904_231411  0.939587  0.179311  0.722893              0.169534  0.226236  0.051183\n",
      "16     DeepLearning_grid_3_AutoML_2_20250904_231411_model_2  0.937687  0.206824  0.747536              0.167009  0.253145  0.064083\n",
      "17     DeepLearning_grid_1_AutoML_2_20250904_231411_model_2  0.937281  0.181686  0.742289              0.160481  0.225556  0.050875\n",
      "18     DeepLearning_grid_3_AutoML_2_20250904_231411_model_1  0.936969  0.191866  0.718256              0.173166  0.230931  0.053329\n",
      "19     DeepLearning_grid_1_AutoML_2_20250904_231411_model_1  0.935486  0.202703  0.729222              0.170997  0.235321  0.055376\n",
      "20                           GLM_1_AutoML_2_20250904_231411  0.932975  0.193584  0.733007              0.172102  0.229785  0.052801\n",
      "21     DeepLearning_grid_2_AutoML_2_20250904_231411_model_1  0.926235  0.201573  0.706861              0.184245  0.234972  0.055212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kinoshitatakashihiroshi/Dropbox/VS_Code/OneICU_profile_paper/.venv/lib/python3.12/site-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n",
      "/Users/kinoshitatakashihiroshi/Dropbox/VS_Code/OneICU_profile_paper/.venv/lib/python3.12/site-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n",
      "2025-09-04 23:21:52,323 INFO === training dataset: mimiciv ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "23:22:00.439: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      "\n",
      "=== leaderboard for mimiciv (rows=22) ===\n",
      "                                                   model_id       auc   logloss     aucpr  mean_per_class_error      rmse       mse\n",
      "0      StackedEnsemble_AllModels_1_AutoML_3_20250904_232200  0.828924  0.258614  0.410010              0.280202  0.273937  0.075042\n",
      "1   StackedEnsemble_BestOfFamily_1_AutoML_3_20250904_232200  0.828051  0.259190  0.409895              0.275477  0.274164  0.075166\n",
      "2               GBM_grid_1_AutoML_3_20250904_232200_model_5  0.827274  0.259696  0.405491              0.282342  0.274495  0.075348\n",
      "3                            GBM_2_AutoML_3_20250904_232200  0.825777  0.260702  0.398696              0.278549  0.275217  0.075744\n",
      "4                            GLM_1_AutoML_3_20250904_232200  0.824442  0.269470  0.397602              0.276640  0.277073  0.076769\n",
      "5      DeepLearning_grid_2_AutoML_3_20250904_232200_model_2  0.823670  0.265014  0.391196              0.284000  0.277183  0.076830\n",
      "6                            GBM_5_AutoML_3_20250904_232200  0.822690  0.263407  0.386868              0.281111  0.276911  0.076680\n",
      "7               GBM_grid_1_AutoML_3_20250904_232200_model_4  0.822110  0.264058  0.381620              0.282006  0.277546  0.077032\n",
      "8      DeepLearning_grid_3_AutoML_3_20250904_232200_model_2  0.822106  0.268846  0.386155              0.287844  0.279004  0.077843\n",
      "9                            GBM_3_AutoML_3_20250904_232200  0.821314  0.263351  0.388389              0.287538  0.276696  0.076561\n",
      "10                           GBM_1_AutoML_3_20250904_232200  0.821266  0.263433  0.389838              0.283224  0.276653  0.076537\n",
      "11              GBM_grid_1_AutoML_3_20250904_232200_model_2  0.820115  0.265046  0.379234              0.283005  0.277987  0.077277\n",
      "12                  DeepLearning_1_AutoML_3_20250904_232200  0.819667  0.263815  0.400775              0.286269  0.275565  0.075936\n",
      "13                           GBM_4_AutoML_3_20250904_232200  0.817394  0.265154  0.383235              0.292921  0.277451  0.076979\n",
      "14              GBM_grid_1_AutoML_3_20250904_232200_model_1  0.816025  0.267541  0.373746              0.283809  0.278725  0.077688\n",
      "15     DeepLearning_grid_1_AutoML_3_20250904_232200_model_2  0.813719  0.268721  0.396586              0.282102  0.277796  0.077171\n",
      "16     DeepLearning_grid_3_AutoML_3_20250904_232200_model_1  0.810524  0.269701  0.382753              0.295446  0.278518  0.077572\n",
      "17              GBM_grid_1_AutoML_3_20250904_232200_model_3  0.807011  0.271725  0.353221              0.295106  0.281108  0.079022\n",
      "18                           DRF_1_AutoML_3_20250904_232200  0.802394  0.281272  0.370057              0.301667  0.284014  0.080664\n",
      "19                           XRT_1_AutoML_3_20250904_232200  0.798570  0.283083  0.367620              0.299092  0.284912  0.081175\n",
      "20     DeepLearning_grid_2_AutoML_3_20250904_232200_model_1  0.798488  0.293177  0.349333              0.299697  0.285004  0.081227\n",
      "21     DeepLearning_grid_1_AutoML_3_20250904_232200_model_1  0.772036  0.302336  0.313032              0.322421  0.288829  0.083422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kinoshitatakashihiroshi/Dropbox/VS_Code/OneICU_profile_paper/.venv/lib/python3.12/site-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n",
      "/Users/kinoshitatakashihiroshi/Dropbox/VS_Code/OneICU_profile_paper/.venv/lib/python3.12/site-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for name in datasets:\n",
    "    logging.info(\"=== training dataset: %s ===\", name)\n",
    "    train_pd = import_train_pd(name)\n",
    "\n",
    "    x = [c for c in train_pd.columns if c not in (target, id_col, time_index_col)]\n",
    "    if not x:\n",
    "        raise ValueError(f\"no feature columns found for {name}.\")\n",
    "\n",
    "    # disjoint patient-level splits for base, blending, leaderboard\n",
    "    base_pd, blend_pd, lb_pd = split_patient_level_pd(\n",
    "        train_pd, id_col=id_col, seed=aml_seed, blend_frac=0.10, lb_frac=0.10\n",
    "    )\n",
    "\n",
    "    base_train = to_h2o_binomial_numeric(base_pd, target, x)\n",
    "    blend      = to_h2o_binomial_numeric(blend_pd, target, x)\n",
    "    lb_frame   = to_h2o_binomial_numeric(lb_pd, target, x)\n",
    "\n",
    "    del train_pd, base_pd, blend_pd, lb_pd\n",
    "    gc.collect()\n",
    "\n",
    "    aml = H2OAutoML(\n",
    "        seed=aml_seed,\n",
    "        nfolds=0,\n",
    "        max_models=20,\n",
    "        max_runtime_secs=aml_max_runtime_secs,\n",
    "        max_runtime_secs_per_model=1800,\n",
    "        sort_metric=aml_sort_metric,\n",
    "    )\n",
    "    aml.train(\n",
    "        x=x,\n",
    "        y=target,\n",
    "        training_frame=base_train,\n",
    "        blending_frame=blend,\n",
    "        leaderboard_frame=lb_frame,\n",
    "    )\n",
    "\n",
    "    # print full leaderboard for this dataset\n",
    "    lb = aml.leaderboard\n",
    "    lb_df = lb.as_data_frame(use_pandas=True, use_multi_thread=True)\n",
    "    print(f\"\\n=== leaderboard for {name} (rows={lb.nrows}) ===\")\n",
    "    print(lb_df.to_string(index=True))\n",
    "\n",
    "    # leader and best glm\n",
    "    leader = aml.leader\n",
    "    glm_model = best_glm_from_automl(aml)\n",
    "\n",
    "    # save models + manifest\n",
    "    leader_path, glm_path = save_models(name, leader, glm_model, x)\n",
    "\n",
    "    # record summary\n",
    "    results[name] = {\n",
    "        \"leader_model_path\": leader_path,\n",
    "        \"glm_model_path\": glm_path,\n",
    "        \"n_features\": len(x),\n",
    "    }\n",
    "\n",
    "    h2o.remove_all()\n",
    "    del aml, leader, glm_model, base_train, blend, lb_frame, lb, lb_df\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83db88c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23be37f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'oneicu': {'leader_model_path': '/Users/kinoshitatakashihiroshi/Dropbox/VS_Code/research-database-description-2024/output/models/oneicu/StackedEnsemble_AllModels_1_AutoML_1_20250904_225743',\n",
       "  'glm_model_path': '/Users/kinoshitatakashihiroshi/Dropbox/VS_Code/research-database-description-2024/output/models/oneicu/GLM_1_AutoML_1_20250904_225743',\n",
       "  'n_features': 70},\n",
       " 'eicu': {'leader_model_path': '/Users/kinoshitatakashihiroshi/Dropbox/VS_Code/research-database-description-2024/output/models/eicu/StackedEnsemble_AllModels_1_AutoML_2_20250904_231411',\n",
       "  'glm_model_path': '/Users/kinoshitatakashihiroshi/Dropbox/VS_Code/research-database-description-2024/output/models/eicu/GLM_1_AutoML_2_20250904_231411',\n",
       "  'n_features': 22},\n",
       " 'mimiciv': {'leader_model_path': '/Users/kinoshitatakashihiroshi/Dropbox/VS_Code/research-database-description-2024/output/models/mimiciv/StackedEnsemble_AllModels_1_AutoML_3_20250904_232200',\n",
       "  'glm_model_path': '/Users/kinoshitatakashihiroshi/Dropbox/VS_Code/research-database-description-2024/output/models/mimiciv/GLM_1_AutoML_3_20250904_232200',\n",
       "  'n_features': 11}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fd42c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2O session _sid_b19b closed.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    h2o.cluster().shutdown(prompt=False)\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6352814e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
